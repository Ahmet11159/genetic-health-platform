"""
GeliÅŸmiÅŸ Caching Sistemi
DNA analiz sonuÃ§larÄ±nÄ± cache'leyerek performansÄ± artÄ±rÄ±r
"""

import json
import hashlib
import os
import time
from typing import Dict, Any, Optional
from datetime import datetime, timedelta
import redis
from pathlib import Path

class DNACacheManager:
    """DNA analiz sonuÃ§larÄ± iÃ§in geliÅŸmiÅŸ cache yÃ¶neticisi"""
    
    def __init__(self, cache_dir: str = "cache", redis_url: str = None):
        """
        Cache yÃ¶neticisini baÅŸlat
        
        Args:
            cache_dir: Cache dosyalarÄ±nÄ±n saklanacaÄŸÄ± dizin
            redis_url: Redis baÄŸlantÄ± URL'si (opsiyonel)
        """
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(exist_ok=True)
        
        # Redis baÄŸlantÄ±sÄ± (opsiyonel)
        self.redis_client = None
        if redis_url:
            try:
                self.redis_client = redis.from_url(redis_url)
                self.redis_client.ping()
                print("âœ… Redis cache aktif")
            except:
                print("âš ï¸ Redis kullanÄ±lamÄ±yor, dosya cache kullanÄ±lacak")
        
        # Cache istatistikleri
        self.stats = {
            'hits': 0,
            'misses': 0,
            'sets': 0,
            'deletes': 0,
            'total_size': 0
        }
    
    def _generate_cache_key(self, dna_data: str, analysis_type: str = "full") -> str:
        """DNA verisinden cache anahtarÄ± oluÅŸtur"""
        # DNA verisinin hash'ini al
        data_hash = hashlib.md5(dna_data.encode()).hexdigest()
        return f"dna_analysis_{analysis_type}_{data_hash}"
    
    def _get_file_path(self, cache_key: str) -> Path:
        """Cache dosya yolunu dÃ¶ndÃ¼r"""
        return self.cache_dir / f"{cache_key}.json"
    
    def get(self, dna_data: str, analysis_type: str = "full") -> Optional[Dict[str, Any]]:
        """
        Cache'den analiz sonucunu al
        
        Args:
            dna_data: DNA verisi
            analysis_type: Analiz tipi (full, health, nutrition, etc.)
            
        Returns:
            Cache'deki analiz sonucu veya None
        """
        cache_key = self._generate_cache_key(dna_data, analysis_type)
        
        try:
            # Ã–nce Redis'i dene
            if self.redis_client:
                cached_data = self.redis_client.get(cache_key)
                if cached_data:
                    result = json.loads(cached_data)
                    # Cache sÃ¼resi kontrolÃ¼
                    if self._is_cache_valid(result):
                        self.stats['hits'] += 1
                        print(f"ğŸ¯ Cache HIT: {analysis_type} analizi")
                        return result['data']
                    else:
                        # SÃ¼resi dolmuÅŸ cache'i sil
                        self.redis_client.delete(cache_key)
            
            # Dosya cache'ini kontrol et
            file_path = self._get_file_path(cache_key)
            if file_path.exists():
                with open(file_path, 'r', encoding='utf-8') as f:
                    result = json.load(f)
                
                if self._is_cache_valid(result):
                    self.stats['hits'] += 1
                    print(f"ğŸ¯ Cache HIT: {analysis_type} analizi (dosya)")
                    return result['data']
                else:
                    # SÃ¼resi dolmuÅŸ dosyayÄ± sil
                    file_path.unlink()
            
            self.stats['misses'] += 1
            print(f"âŒ Cache MISS: {analysis_type} analizi")
            return None
            
        except Exception as e:
            print(f"âš ï¸ Cache okuma hatasÄ±: {e}")
            self.stats['misses'] += 1
            return None
    
    def set(self, dna_data: str, analysis_result: Dict[str, Any], 
            analysis_type: str = "full", ttl_hours: int = 24) -> bool:
        """
        Analiz sonucunu cache'e kaydet
        
        Args:
            dna_data: DNA verisi
            analysis_result: Analiz sonucu
            analysis_type: Analiz tipi
            ttl_hours: Cache sÃ¼resi (saat)
            
        Returns:
            BaÅŸarÄ± durumu
        """
        cache_key = self._generate_cache_key(dna_data, analysis_type)
        
        cache_data = {
            'data': analysis_result,
            'created_at': datetime.now().isoformat(),
            'expires_at': (datetime.now() + timedelta(hours=ttl_hours)).isoformat(),
            'analysis_type': analysis_type,
            'data_size': len(json.dumps(analysis_result))
        }
        
        try:
            # Redis'e kaydet
            if self.redis_client:
                self.redis_client.setex(
                    cache_key, 
                    ttl_hours * 3600,  # saniye cinsinden
                    json.dumps(cache_data)
                )
                print(f"ğŸ’¾ Redis cache'e kaydedildi: {analysis_type}")
            
            # Dosya cache'ine kaydet
            file_path = self._get_file_path(cache_key)
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(cache_data, f, ensure_ascii=False, indent=2)
            
            self.stats['sets'] += 1
            self.stats['total_size'] += cache_data['data_size']
            print(f"ğŸ’¾ Dosya cache'e kaydedildi: {analysis_type}")
            return True
            
        except Exception as e:
            print(f"âŒ Cache kaydetme hatasÄ±: {e}")
            return False
    
    def _is_cache_valid(self, cache_data: Dict[str, Any]) -> bool:
        """Cache'in geÃ§erli olup olmadÄ±ÄŸÄ±nÄ± kontrol et"""
        try:
            expires_at = datetime.fromisoformat(cache_data['expires_at'])
            return datetime.now() < expires_at
        except:
            return False
    
    def delete(self, dna_data: str, analysis_type: str = "full") -> bool:
        """Cache'den analiz sonucunu sil"""
        cache_key = self._generate_cache_key(dna_data, analysis_type)
        
        try:
            # Redis'ten sil
            if self.redis_client:
                self.redis_client.delete(cache_key)
            
            # Dosyadan sil
            file_path = self._get_file_path(cache_key)
            if file_path.exists():
                file_path.unlink()
            
            self.stats['deletes'] += 1
            print(f"ğŸ—‘ï¸ Cache silindi: {analysis_type}")
            return True
            
        except Exception as e:
            print(f"âŒ Cache silme hatasÄ±: {e}")
            return False
    
    def clear_expired(self) -> int:
        """SÃ¼resi dolmuÅŸ cache'leri temizle"""
        cleared_count = 0
        
        try:
            # Dosya cache'lerini kontrol et
            for file_path in self.cache_dir.glob("*.json"):
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        cache_data = json.load(f)
                    
                    if not self._is_cache_valid(cache_data):
                        file_path.unlink()
                        cleared_count += 1
                        print(f"ğŸ—‘ï¸ SÃ¼resi dolmuÅŸ cache silindi: {file_path.name}")
                        
                except Exception as e:
                    print(f"âš ï¸ Cache dosyasÄ± okunamadÄ±: {file_path.name} - {e}")
            
            print(f"âœ… {cleared_count} sÃ¼resi dolmuÅŸ cache temizlendi")
            return cleared_count
            
        except Exception as e:
            print(f"âŒ Cache temizleme hatasÄ±: {e}")
            return 0
    
    def get_stats(self) -> Dict[str, Any]:
        """Cache istatistiklerini dÃ¶ndÃ¼r"""
        hit_rate = 0
        if self.stats['hits'] + self.stats['misses'] > 0:
            hit_rate = self.stats['hits'] / (self.stats['hits'] + self.stats['misses'])
        
        return {
            **self.stats,
            'hit_rate': round(hit_rate * 100, 2),
            'cache_dir': str(self.cache_dir),
            'redis_active': self.redis_client is not None
        }
    
    def cleanup_old_files(self, days: int = 7) -> int:
        """Belirtilen gÃ¼nden eski dosyalarÄ± temizle"""
        cutoff_time = time.time() - (days * 24 * 3600)
        cleaned_count = 0
        
        try:
            for file_path in self.cache_dir.glob("*.json"):
                if file_path.stat().st_mtime < cutoff_time:
                    file_path.unlink()
                    cleaned_count += 1
                    print(f"ğŸ—‘ï¸ Eski dosya silindi: {file_path.name}")
            
            print(f"âœ… {cleaned_count} eski dosya temizlendi")
            return cleaned_count
            
        except Exception as e:
            print(f"âŒ Eski dosya temizleme hatasÄ±: {e}")
            return 0

# Global cache manager instance
cache_manager = DNACacheManager()
